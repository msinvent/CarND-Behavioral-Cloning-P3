{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv,cv2, numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16072, 160, 320, 3) (16072,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data Extraction Phase\n",
    "This block is reading the files and placing into numpy arrays that\n",
    "will be preprocessed and finally fed into the deep neural network\n",
    "'''\n",
    "\n",
    "\n",
    "uploadFromPreviousRun = np.load('../assignment_3/data_downloaded/data/Behavioral_Cloning_1_8036.npz')\n",
    "X_train = uploadFromPreviousRun['X_train']\n",
    "y_train = uploadFromPreviousRun['y_train']\n",
    "print(X_train.shape,y_train.shape)\n",
    "\n",
    "\n",
    "## Data Appending\n",
    "# uploadFromPreviousRun1 = np.load('../assignment_3/data_downloaded/data/Behavioral_Cloning_1_7000.npz')\n",
    "# uploadFromPreviousRun2 = np.load('../assignment_3/data_downloaded/data/Behavioral_Cloning_7000_8036.npz')\n",
    "\n",
    "# X_train1 = uploadFromPreviousRun1['X_train']\n",
    "# y_train1 = uploadFromPreviousRun1['y_train']\n",
    "\n",
    "# X_train2 = uploadFromPreviousRun2['X_train']\n",
    "# y_train2 = uploadFromPreviousRun2['y_train']\n",
    "\n",
    "# print(X_train1.shape,y_train1.shape)\n",
    "# print(X_train2.shape,y_train2.shape)\n",
    "\n",
    "# # y_train1 = uploadFromPreviousRun1['y_train']\n",
    "# # y_train2 = uploadFromPreviousRun2['y_train']\n",
    "\n",
    "# X_train1 = np.append(X_train1,X_train2,axis=0)\n",
    "# y_train1 = np.append(y_train1,y_train2,axis=0)\n",
    "# print(X_train1.shape,y_train1.shape)\n",
    "\n",
    "# np.savez_compressed('../assignment_3/data_downloaded/data/Behavioral_Cloning_1_8036',X_train=X_train1,y_train=y_train1)\n",
    "\n",
    "\n",
    "## Reading real file\n",
    "# # relativeLocation = '../assignment_3/data/lane1/'\n",
    "# relativeLocation = '../assignment_3/data_downloaded/data/'\n",
    "# df = pd.read_csv(relativeLocation + 'driving_log.csv')\n",
    "\n",
    "# ## Initialization\n",
    "# # Initialization of numpy array with the first image is already done\n",
    "# counterStart = 7000\n",
    "# counterNumImagesMax = 1036\n",
    "# X_train = np.empty((0,160,320,3),np.uint8)\n",
    "# y_train = np.array(df['steering'])[counterStart:counterStart+counterNumImagesMax]\n",
    "\n",
    "# counterNumImages = 0\n",
    "# ## Extraction loop\n",
    "# for imageName in df['center'][counterStart:counterStart + counterNumImagesMax]:\n",
    "#     image_path = relativeLocation + '/IMG/' + imageName.split('/')[-1]\n",
    "#     new_image = cv2.imread(image_path)\n",
    "    \n",
    "#     new_image = cv2.imread(image_path).reshape((1,160,320,3))\n",
    "#     X_train = np.append(X_train,new_image,axis=0)\n",
    "    \n",
    "#     counterNumImages = counterNumImages+1\n",
    "#     print(counterNumImages)\n",
    "#     if counterNumImages == counterNumImagesMax:\n",
    "#         break\n",
    "\n",
    "        \n",
    "# X_train_Flipped = np.empty((0,160,320,3),np.uint8)\n",
    "# # Add mirror_image into the data\n",
    "# for image in X_train:\n",
    "#     flippedImage = np.fliplr(image).copy() #Comment 1 : this copy looks important\n",
    "#      #fliplr just flips something that is not data\n",
    "#     X_train_Flipped = np.append(X_train_Flipped,new_image,axis=0)\n",
    "#     counterNumImages = counterNumImages + 1\n",
    "#     print(counterNumImages)\n",
    "\n",
    "    \n",
    "# X_train = np.append(X_train,X_train_Flipped,axis=0)\n",
    "# y_train = np.append(y_train,-y_train)\n",
    "\n",
    "# print(X_train.shape,y_train.shape)\n",
    "\n",
    "# np.savez_compressed('../assignment_3/data_downloaded/data/Behavioral_Cloning_7000_8036',X_train=X_train,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each image is of shape :  (160, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Data PreAnalysis Phase\n",
    "Look at the max and min values of the Steering, Throttle, Break, Speed\n",
    "'''\n",
    "print('Each image is of shape : ',X_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Keral library imports\n",
    "'''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Lambda, Cropping2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12857 samples, validate on 3215 samples\n",
      "Epoch 1/11\n",
      "12857/12857 [==============================] - 12s 960us/step - loss: 0.1773 - val_loss: 0.0216\n",
      "Epoch 2/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0170 - val_loss: 0.0163\n",
      "Epoch 3/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0141 - val_loss: 0.0194\n",
      "Epoch 4/11\n",
      "12857/12857 [==============================] - 8s 612us/step - loss: 0.0127 - val_loss: 0.0181\n",
      "Epoch 5/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0122 - val_loss: 0.0190\n",
      "Epoch 6/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0123 - val_loss: 0.0178\n",
      "Epoch 7/11\n",
      "12857/12857 [==============================] - 8s 611us/step - loss: 0.0116 - val_loss: 0.0187\n",
      "Epoch 8/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0114 - val_loss: 0.0171\n",
      "Epoch 9/11\n",
      "12857/12857 [==============================] - 8s 608us/step - loss: 0.0111 - val_loss: 0.0171\n",
      "Epoch 10/11\n",
      "10368/12857 [=======================>......] - ETA: 1s - loss: 0.0109"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Keral network description\n",
    "'''\n",
    "\n",
    "# Graph Description\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160,320,3))) #Normalization layer\n",
    "model.add(Cropping2D(cropping=((70,25),(10,10))))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "\n",
    "# Network optimization choices set to mse and adam optimizer\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "          \n",
    "# Network training happening here\n",
    "model.fit(X_train,y_train, validation_split=0.2, shuffle=True, epochs = 11)\n",
    "model.save('model_11A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
