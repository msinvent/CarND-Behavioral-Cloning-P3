{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv,cv2, numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "# https://github.com/shervinea/enzynet\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, labels, batch_size=32, dim=(32,32,32), shuffle=False, objectName = 'defaultName', **params):\n",
    "#         'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        self.indexes = list_IDs.index\n",
    "        self.relativeLocation  = relativeLocation\n",
    "        self.objectName = objectName\n",
    "\n",
    "    def __len__(self):\n",
    "#         'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "#         print(self.objectName, '\\n\\n', indexes)\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(indexes)\n",
    "        return X, y\n",
    "\n",
    "    def __on_epoch_end(self):\n",
    "#         'Updates indexes after each epoch'\n",
    "#         self.indexes = np.arange(len(self.list_IDs))\n",
    "#         print(self.objectName, ': original indexes order : ',self.indexes)\n",
    "#         print(self.objectName, '\\n')\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "#         print(self.objectName, ': reshuffling happening here, new index order is : \\n\\n',self.indexes)\n",
    "            print('shuffling happening here')\n",
    "        \n",
    "    def __data_generation(self, indexes):\n",
    "#         'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim))\n",
    "        y = np.empty((self.batch_size))\n",
    "        \n",
    "        i = 0\n",
    "        for index in indexes:\n",
    "            try:\n",
    "                imageName = self.list_IDs[index]\n",
    "                # index missing thus throw indexError\n",
    "                steeringInput = self.labels[index]\n",
    "                \n",
    "                if(pd.isnull(imageName) or pd.isnull(steeringInput)):\n",
    "#                     print(imageName,steeringInput)\n",
    "                    raise IndexError()\n",
    "                \n",
    "                try:\n",
    "                    image_path = self.relativeLocation + 'IMG/' + imageName.split('/')[-1]\n",
    "                    image = cv2.imread(image_path).reshape((1,160,320,3))\n",
    "               \n",
    "                    if image is None:\n",
    "                        raise IndexError()\n",
    "                                    \n",
    "                    X[i,] = image\n",
    "                    y[i,] = steeringInput\n",
    "                    i = i+1\n",
    "                except IndexError:\n",
    "                    print(self.objectName,' ,inner index ',index,' Either image or steering angle is missing')\n",
    "                    pass\n",
    "                except KeyError:\n",
    "                    print(self.objectName,' ,inner key ',index,' Either image or steering angle is missing')\n",
    "                    pass\n",
    "        \n",
    "        \n",
    "        \n",
    "            except IndexError:\n",
    "                print(self.objectName,' ,outer index ',index,' Either image or steering angle is missing')\n",
    "                pass\n",
    "            except KeyError:\n",
    "                print(self.objectName,' ,outer key ',index,' Either image or steering angle is missing')\n",
    "                pass\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (160,320,3),\n",
    "          'batch_size': 128,\n",
    "          'shuffle': True,\n",
    "          'relativeLocation':'../assignment_3/data_downloaded/data/'}\n",
    "\n",
    "# Datasets\n",
    "relativeLocation = params['relativeLocation']\n",
    "df = pd.read_csv(relativeLocation + 'driving_log.csv')\n",
    "X = df['center']\n",
    "y = df['steering']\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "training_generator = DataGenerator(X_train, y_train, objectName = 'trainingGenerator', **params)\n",
    "validation_generator = DataGenerator(X_validation, y_validation, objectName = 'validationGenerator', **params)\n",
    "\n",
    "# Some Debugging happening here\n",
    "XX, yy = training_generator.__getitem__(0)\n",
    "XX, yy = validation_generator.__getitem__(0)\n",
    "# print(yy)\n",
    "# for image in XX:\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plt.imshow(image) # This is showig the image thinking it is a bgr image\n",
    "#     print(image)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# Keral library imports\n",
    "# '''\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Lambda, Cropping2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 85, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 42, 159, 24)       672       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 79, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 21, 79, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 39, 36)        7812      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 19, 36)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 19, 36)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 9, 48)          15600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 4, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               19300     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                3030      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 46,445\n",
      "Trainable params: 46,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ch, row, col = 3, 80, 320  # Trimmed image format\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/255.0 - 0.5, input_shape=(160,320,3))) #Normalization layer\n",
    "model.add(Cropping2D(cropping=((60,15),(0,0))))\n",
    "\n",
    "model.add(Conv2D(24, activation=\"relu\", kernel_size=(3, 3), strides=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(36, activation=\"relu\", kernel_size=(3, 3), strides=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Conv2D(48, activation=\"relu\", kernel_size=(3, 3), strides=(2, 2)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(30))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # Network optimization choices set to mse and adam optimizer\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "          \n",
    "# # Network training happening here\n",
    "# # model..fit_generator(train_generator, samples_per_epoch=len(train_samples), validation_data=validation_generator,\n",
    "# #                     nb_val_samples=len(validation_samples), epochs=3)\n",
    "# # model.fit_generator(train_generator, steps_per_epoch= len(train_samples),\n",
    "# # validation_data=validation_generator, validation_steps=len(validation_samples), epochs=5, verbose = 1)\n",
    "\n",
    "# # model.save('model_3A.h5')\n",
    "\n",
    "\n",
    "# # Design model\n",
    "# model = Sequential()\n",
    "# [...] # Architecture\n",
    "# model.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 55s - loss: 0.0474 - val_loss: 0.0384\n",
      "Epoch 2/8\n",
      " - 54s - loss: 0.0333 - val_loss: 0.0333\n",
      "Epoch 3/8\n",
      " - 54s - loss: 0.0309 - val_loss: 0.0339\n",
      "Epoch 4/8\n",
      " - 54s - loss: 0.0288 - val_loss: 0.0321\n",
      "Epoch 5/8\n",
      " - 54s - loss: 0.0275 - val_loss: 0.0301\n",
      "Epoch 6/8\n",
      " - 54s - loss: 0.0264 - val_loss: 0.0288\n",
      "Epoch 7/8\n",
      " - 54s - loss: 0.0254 - val_loss: 0.0285\n",
      "Epoch 8/8\n",
      " - 54s - loss: 0.0248 - val_loss: 0.0330\n"
     ]
    }
   ],
   "source": [
    "# Train model on dataset\n",
    "\n",
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle = True,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    epochs = 8,\n",
    "                    workers=4,\n",
    "                    verbose=2)\n",
    "\n",
    "model.save('model_generators_8C.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 54s - loss: 0.0247 - val_loss: 0.0329\n",
      "Epoch 2/8\n",
      " - 54s - loss: 0.0232 - val_loss: 0.0293\n",
      "Epoch 3/8\n",
      " - 54s - loss: 0.0232 - val_loss: 0.0259\n",
      "Epoch 4/8\n",
      " - 53s - loss: 0.0229 - val_loss: 0.0272\n",
      "Epoch 5/8\n",
      " - 53s - loss: 0.0221 - val_loss: 0.0283\n",
      "Epoch 6/8\n",
      " - 53s - loss: 0.0221 - val_loss: 0.0259\n",
      "Epoch 7/8\n",
      " - 53s - loss: 0.0216 - val_loss: 0.0266\n",
      "Epoch 8/8\n",
      " - 53s - loss: 0.0207 - val_loss: 0.0268\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle = True,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    epochs = 8,\n",
    "                    workers=4,\n",
    "                    verbose=2)\n",
    "\n",
    "model.save('model_generators_16C.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 53s - loss: 0.0215 - val_loss: 0.0288\n",
      "Epoch 2/8\n",
      " - 53s - loss: 0.0210 - val_loss: 0.0260\n",
      "Epoch 3/8\n",
      " - 52s - loss: 0.0211 - val_loss: 0.0258\n",
      "Epoch 4/8\n",
      " - 53s - loss: 0.0207 - val_loss: 0.0253\n",
      "Epoch 5/8\n",
      " - 53s - loss: 0.0201 - val_loss: 0.0273\n",
      "Epoch 6/8\n",
      " - 53s - loss: 0.0196 - val_loss: 0.0254\n",
      "Epoch 7/8\n",
      " - 53s - loss: 0.0199 - val_loss: 0.0230\n",
      "Epoch 8/8\n",
      " - 53s - loss: 0.0195 - val_loss: 0.0270\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle = True,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    epochs = 8,\n",
    "                    workers=4,\n",
    "                    verbose=2)\n",
    "\n",
    "model.save('model_generators_24C.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 53s - loss: 0.0190 - val_loss: 0.0274\n",
      "Epoch 2/8\n",
      " - 53s - loss: 0.0189 - val_loss: 0.0233\n",
      "Epoch 3/8\n",
      " - 53s - loss: 0.0189 - val_loss: 0.0273\n",
      "Epoch 4/8\n",
      " - 53s - loss: 0.0194 - val_loss: 0.0266\n",
      "Epoch 5/8\n",
      " - 53s - loss: 0.0195 - val_loss: 0.0267\n",
      "Epoch 6/8\n",
      " - 53s - loss: 0.0183 - val_loss: 0.0264\n",
      "Epoch 7/8\n",
      " - 53s - loss: 0.0185 - val_loss: 0.0281\n",
      "Epoch 8/8\n",
      " - 53s - loss: 0.0176 - val_loss: 0.0250\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle = True,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    epochs = 8,\n",
    "                    workers=4,\n",
    "                    verbose=2)\n",
    "\n",
    "model.save('model_generators_32C.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " - 53s - loss: 0.0176 - val_loss: 0.0287\n",
      "Epoch 2/8\n",
      " - 53s - loss: 0.0180 - val_loss: 0.0244\n",
      "Epoch 3/8\n",
      " - 53s - loss: 0.0176 - val_loss: 0.0240\n",
      "Epoch 4/8\n",
      " - 52s - loss: 0.0180 - val_loss: 0.0218\n",
      "Epoch 5/8\n",
      " - 54s - loss: 0.0171 - val_loss: 0.0219\n",
      "Epoch 6/8\n",
      " - 53s - loss: 0.0178 - val_loss: 0.0274\n",
      "Epoch 7/8\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(generator=training_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    use_multiprocessing=False,\n",
    "                    shuffle = True,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    epochs = 8,\n",
    "                    workers=4,\n",
    "                    verbose=2)\n",
    "\n",
    "model.save('model_generators_40C.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
